Emmett James Thompson

# Neuropixel Data Preprocessing  
Scripts for processing data collected during electrophysiology (ephys) recordings for the 8-port sequence task.  

- See our publication for more details: [Replay of Procedural Experience is Independent of the Hippocampus](https://www.biorxiv.org/content/10.1101/2024.06.05.597547v1.full.pdf).

## Overview  
This repository provides a pipeline for processing three main data streams:  
1. **Electrophysiology (ephys)**  
2. **Behavioral data**  
3. **Video data**  

The workflow includes initial processing (scripts 1â€“5) and final alignment to create a synchronization file. The output is organized into a clean, structured directory.  

![Processing pipeline](images/processing_schematic.png)  

---

## Data Collection  
This pipeline assumes data collected with the following setup:  
- **Neuropixels (1.0 or 2.0):** Recorded using Open Ephys.  
- **Behavioral data:** Collected with Bpod using the "Sequence Automated" protocol.  
- **Video data:** Recorded using FLIR cameras positioned above and below the task/sleep arenas. Triggers sent via GPIO. Video (`.avi`) and timestamps (`.csv`) saved through Bonsai.  
- **Synchronization:** TTL pulses (see **TTL Alignment** section).  

---

## Processing Pipeline  

The pipeline is organized into six sequential phases:  

### 1. Ephys Processing  
Processes raw ephys data (Open Ephys output) using the **SpikeInterface** framework and spike sorts the data with **Kilosort 4**.  

**Requirements:**  
- [SpikeInterface](https://spikeinterface.readthedocs.io/en/stable/)  
- [Kilosort 4](https://github.com/MouseLand/Kilosort)  
  - *Note:* GPU access is recommended for faster processing. See `HPC_helpsheet` for cluster computing tips.  

**Output:**  
- Organized file directories for each recording.  
- Kilosort outputs (spike times) for each probe.  

---

### 2. Video Processing  
Processes video files (`.avi`) and timestamps (`.csv`) generated by Bonsai:  
1. Converts timestamps into seconds.  
2. Labels the three experimental phases of the videos using trigger times (see **TTL Alignment**).  
3. Automatically detects and labels camera views (back or top).  

**Output:**  
- Renamed and organized `.avi` files.  
- Copies of raw files in a dump folder for subsequent **DeepLabCut** tracking.  
- Timestamp DataFrames for each video.  

---

### 3. Video Tracking  
Generates tracking files for video data:  
1. Creates `.sh` shell scripts for **DeepLabCut** processing on a cluster.
2. These files reply on a ".py" file called **dlc_on_hpc**
3. This file is located in "other_files" and needs to be moved to the same location as the ".sh" files which call it. 
4. Tracks behavioral ports and mouse head center.  

**Requirements:**  
- [DeepLabCut](https://deeplabcut.github.io/DeepLabCut/README.html)  
- See `HPC_helpsheet` for cluster usage guidance.  

**Output:**  
- Tracking files in the organized directory.  

---

### 4. Bpod Processing  
Processes raw `.mat` files from Bpod into a Python-readable format. Update file paths before use.  

**Output:**  
- Processed behavioral data files in the organized directory.  

---

### 5. Probe Localization  
Determines brain locations of Kilosorted units using:  
1. **Spectral Analysis**  
   - Analyzes ephys signals across the probe.  
   - *Note:* Multiple recordings across the probe length improve accuracy.  
2. **Histology**  
   - Perfuse and image the brain.  
   - Align sections to the Allen Brain Atlas using [brainreg](https://brainglobe.info/documentation/brainreg/index.html).  
   - Trace probe tracks with [brainreg-segment](https://brainglobe.info/documentation/brainglobe-segmentation/index.html).  

**Output:**  
- Spectral analysis results or histology-based probe tracks.  

---

### 6. Data Alignment  
Aligns all datasets (ephys, behavior, video) to a common timeframe. Update file paths before running the script.  

**Output:**  
- Spike DataFrames with depth and brain region information.  
- Synchronization files aligning behavior, ephys, and video data.  

---

## TTL Alignment  

The Bpod behavioral controller serves as the central clock, sending TTL pulses to:  
- **Ephys** (via niDAQ)  
- **Cameras** (via GPIO)  

During sleep, TTL pulses are sent every 30 seconds. During tasks, TTLs are triggered by the trial structure.  

![TTL Clock](images/ttl_clock.png)  
TTL signals during tasks:  
1. Go high when a new trial starts.  
2. Stay high until the mouse initiates the sequence task (first correct port).  

![TTL Task Structure](images/TTL_task_structure.png)  
![Task TTL Relationship](images/task_ttl_relationship.png)  

---

## Getting Started  

### Prerequisites  
Ensure the following software is installed:  
- [Git](https://git-scm.com/)  
- [Python 3.12.3](https://www.python.org/downloads/)  
- Jupyter Notebook  
- Python libraries (see `requirements.txt`).  
  - *Note:* Some dependencies may be redundant or missing but should be easy to identify.  
- **Important:** Use `moviepy` version `1.0.3`. Newer versions (as of December 2024) are broken.  

---

This repo and the documentation is not at all comprehensive and designed for my data structures. If you need further assistance or have questions about adaoting these scripts for your needs feel free to contact me


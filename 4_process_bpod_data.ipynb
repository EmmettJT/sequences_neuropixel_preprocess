{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import functions from .py utils file: \n",
    "from Utilities.preprocessing import *\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputPath = r\"Z:\\projects\\sequence_squad\\revision_data\\lars_recordings\\bpod_data\\\\\"\n",
    "# InputPath = r\"D:\\EPHYS_BPOD_data_example\\\\\"\n",
    "\n",
    "out_path_base = r\"Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\\"\n",
    "\n",
    "Replace = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# find main paths for the animals\n",
    "main_paths = []\n",
    "Animal_ID = []\n",
    "Animal_save_paths = []\n",
    "Animal_bpod_save_paths = []\n",
    "Animal_ephys_dates = []\n",
    "for mouse in os.listdir(InputPath):\n",
    "    if not mouse == 'FakeSubject':\n",
    "        Animal_ID += [mouse]\n",
    "        main_paths+=[os.path.join(InputPath,mouse,r'Sequence_Automated','Session Data//')]\n",
    "        \n",
    "        # find dates that match an ephys recording \n",
    "        for animal_file in os.listdir(out_path_base):\n",
    "            # for seq00 animals\n",
    "            if mouse.lower() in animal_file:\n",
    "                recordings = os.listdir(os.path.join(out_path_base,animal_file))\n",
    "                ephys_dates = list(recording.split('_')[-1] for recording in recordings)\n",
    "                save_paths = list(os.path.join(out_path_base,animal_file,recording) for recording in recordings)\n",
    "                ## extract date from recordings\n",
    "            elif 'ap5' in mouse.lower():\n",
    "                if 'lr' in mouse.lower():\n",
    "                    recordings = os.listdir(os.path.join(out_path_base,'ap5lr_implant1'))\n",
    "                elif 'L' in mouse:\n",
    "                    recordings = os.listdir(os.path.join(out_path_base,'ap5L_implant1'))\n",
    "                elif 'R' in mouse:\n",
    "                    recordings = os.listdir(os.path.join(out_path_base,'ap5R_implant1'))\n",
    "                ephys_dates = list(recording.split('_')[-1] for recording in recordings)\n",
    "                save_paths = list(os.path.join(out_path_base,animal_file,recording) for recording in recordings)\n",
    "                \n",
    "\n",
    "        # create full save paths    \n",
    "        full_save_paths = []\n",
    "        for save_path in save_paths:\n",
    "            new_path = os.path.join(save_path,r'behav_sync/2_task/')\n",
    "            if not os.path.isdir(new_path):\n",
    "                os.makedirs(new_path)\n",
    "            full_save_paths+=[new_path]\n",
    "        Animal_bpod_save_paths += [full_save_paths]\n",
    "        Animal_save_paths += [save_paths]\n",
    "        Animal_ephys_dates += [ephys_dates]\n",
    "        \n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18-11-2024', '19-11-2024']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Processing data for: AP5_1_L</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP5_1_L_Sequence_Automated_20241116_165741.mat\n",
      "AP5_1_L_Sequence_Automated_20241118_152808.mat\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m display(HTML(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<b>Processing data for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCurrentAnimal\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m</b>\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#Load Behavioural data:\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m Behav_data, Sessions,Path,FileDates \u001b[38;5;241m=\u001b[39m \u001b[43mImport_EPHYS_Bpod_DataFiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mAnimal_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mephys_dates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m Processed \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m Skipped \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Emmett Thompson\\OneDrive\\Documents\\neuropixels_preprocess\\Utilities\\preprocessing.py:623\u001b[0m, in \u001b[0;36mImport_EPHYS_Bpod_DataFiles\u001b[1;34m(InputPath, ephys_dates)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m ephys_dates:\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28mprint\u001b[39m(file)\n\u001b[1;32m--> 623\u001b[0m     Current_file \u001b[38;5;241m=\u001b[39m \u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mInputPath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    624\u001b[0m     Behav_Data[Sessions] \u001b[38;5;241m=\u001b[39m Current_file\n\u001b[0;32m    625\u001b[0m     Sessions \u001b[38;5;241m=\u001b[39m Sessions \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Emmett Thompson\\OneDrive\\Documents\\neuropixels_preprocess\\Utilities\\preprocessing.py:47\u001b[0m, in \u001b[0;36mloadmat\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloadmat\u001b[39m(filename):\n\u001b[0;32m     41\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m    this function should be called instead of direct spio.loadmat\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m    as it cures the problem of not properly recovering python dictionaries\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    from mat files. It calls the function check keys to cure all entries\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m    which are still mat-objects\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstruct_as_record\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msqueeze_me\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m check_keys(data)\n",
      "File \u001b[1;32mc:\\miniconda\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:227\u001b[0m, in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    226\u001b[0m     MR, _ \u001b[38;5;241m=\u001b[39m mat_reader_factory(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 227\u001b[0m     matfile_dict \u001b[38;5;241m=\u001b[39m \u001b[43mMR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariable_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mdict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m     mdict\u001b[38;5;241m.\u001b[39mupdate(matfile_dict)\n",
      "File \u001b[1;32mc:\\miniconda\\Lib\\site-packages\\scipy\\io\\matlab\\_mio5.py:333\u001b[0m, in \u001b[0;36mMatFile5Reader.get_variables\u001b[1;34m(self, variable_names)\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 333\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_var_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhdr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MatReadError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    335\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    336\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnreadable variable \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, because \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    337\u001b[0m         \u001b[38;5;167;01mWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\miniconda\\Lib\\site-packages\\scipy\\io\\matlab\\_mio5.py:291\u001b[0m, in \u001b[0;36mMatFile5Reader.read_var_array\u001b[1;34m(self, header, process)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_var_array\u001b[39m(\u001b[38;5;28mself\u001b[39m, header, process\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    275\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m''' Read array, given `header`\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;124;03m       `process`.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matrix_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_from_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m_mio5_utils.pyx:665\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio5_utils.pyx:712\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio5_utils.pyx:965\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_struct\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio5_utils.pyx:663\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_mi_matrix\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio5_utils.pyx:712\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio5_utils.pyx:965\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_struct\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio5_utils.pyx:663\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_mi_matrix\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio5_utils.pyx:734\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio_utils.pyx:11\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio_utils.squeeze_element\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio_utils.pyx:18\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio_utils.squeeze_element\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\miniconda\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:1487\u001b[0m, in \u001b[0;36m_squeeze_dispatcher\u001b[1;34m(a, axis)\u001b[0m\n\u001b[0;32m   1482\u001b[0m     a \u001b[38;5;241m=\u001b[39m concatenate((a,) \u001b[38;5;241m*\u001b[39m repeats)[:new_size]\n\u001b[0;32m   1484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reshape(a, new_shape)\n\u001b[1;32m-> 1487\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_squeeze_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a,)\n\u001b[0;32m   1491\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_squeeze_dispatcher)\n\u001b[0;32m   1492\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msqueeze\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "        \n",
    "#### MAIN ####\n",
    "for Animal_index, CurrentAnimal in enumerate(Animal_ID):\n",
    "    display(HTML(f\"<b>Processing data for: {CurrentAnimal}</b>\"))\n",
    "    \n",
    "    #Load Behavioural data:\n",
    "    Behav_data, Sessions,Path,FileDates = Import_EPHYS_Bpod_DataFiles(main_paths[Animal_index],Animal_ephys_dates[0])\n",
    "    \n",
    "    Processed = ('')\n",
    "    Skipped = ('')\n",
    "\n",
    "    for Session in tqdm(range(0, Sessions)):\n",
    "\n",
    "        print(Session)\n",
    "\n",
    "        filedate = FileDates[Session] + '_' + str(Behav_data[Session]['__header__'])[-25:-22]\n",
    "\n",
    "        if Session < 10:\n",
    "            Save_path = (Animal_save_paths[Animal_index][Session] + r'\\\\'+ r'\\behav_sync\\2_task\\Preprocessed' + r'\\\\0' + str(Session) + '_' + filedate)\n",
    "        else:\n",
    "            Save_path = (Animal_save_paths[Animal_index][Session] + r'\\\\' + r'\\behav_sync\\2_task\\Preprocessed' + r'\\\\' + str(Session) + '_' + filedate)\n",
    "            \n",
    "            \n",
    "        print(Save_path)\n",
    "\n",
    "        # see if dir exists already then use bool logic to detemrine if it needs to be processed or not\n",
    "        Process = check_and_create_directory(Save_path, Replace)\n",
    "\n",
    "        if Process == True:\n",
    "        \n",
    "            #Convert to python friendly format:\n",
    "            convert_nested_structs(Behav_data[Session])\n",
    "\n",
    "        #    # Extract GUI info\n",
    "            Trial_settings = todict(Behav_data[Session]['SessionData']['TrialSettings'][0])\n",
    "            FinalRewardAmount = []\n",
    "            for item in Behav_data[Session]['SessionData']['SessionVariables']['TLevel']:\n",
    "                TLevel = item\n",
    "                FinalRewardAmount = FinalRewardAmount + [Behav_data[Session]['SessionData']['SessionVariables']['TrainingLevels'][TLevel-1][4]]\n",
    "\n",
    "            # save out training levels on their own\n",
    "            filename = 'Preprocessed_TrainingLevels' \n",
    "            with open(Save_path + r'\\\\'+ filename, 'wb') as fp:\n",
    "                pickle.dump(Behav_data[Session]['SessionData']['SessionVariables']['TLevel'], fp)\n",
    "\n",
    "            # save out led intensites and reward amounts on their own:\n",
    "            LED_Intensities = pd.DataFrame({'Port1':Behav_data[Session]['SessionData']['SessionVariables']['LEDIntensitys']['port1'],\n",
    "                                            'Port2':Behav_data[Session]['SessionData']['SessionVariables']['LEDIntensitys']['port2'],\n",
    "                                            'Port3':Behav_data[Session]['SessionData']['SessionVariables']['LEDIntensitys']['port3'],\n",
    "                                            'Port4':Behav_data[Session]['SessionData']['SessionVariables']['LEDIntensitys']['port4'],\n",
    "                                            'Port5':Behav_data[Session]['SessionData']['SessionVariables']['LEDIntensitys']['port5']})\n",
    "            LED_Intensities.to_csv(Save_path + '/Preprocessed_LED_Intensities.csv')\n",
    "            RewardAmounts = pd.DataFrame({'Port1':Behav_data[Session]['SessionData']['SessionVariables']['RewardAmount']['port1'],\n",
    "                                           'Port2':Behav_data[Session]['SessionData']['SessionVariables']['RewardAmount']['port2'],\n",
    "                                           'Port3':Behav_data[Session]['SessionData']['SessionVariables']['RewardAmount']['port3'],\n",
    "                                           'Port4':Behav_data[Session]['SessionData']['SessionVariables']['RewardAmount']['port4'],\n",
    "                                           'Port5':Behav_data[Session]['SessionData']['SessionVariables']['RewardAmount']['port5']})\n",
    "            RewardAmounts.to_csv(Save_path + '/Preprocessed_RewardAmounts.csv')\n",
    "\n",
    "\n",
    "            #Extract PortIn times for each port and check for errors (inside this function):\n",
    "            All_PortIn_Times,All_PortOut_Times,All_Port_references = extract_poke_times(Behav_data[Session])\n",
    "\n",
    "            #remove nans (times when part [in or out poke] of the event was dropped for some reason by bpod)\n",
    "            All_PortIn_Times_fixed,All_PortOut_Times_fixed ,All_Port_references_fixed = remove_dropped_in_events(All_PortIn_Times,All_PortOut_Times,All_Port_references)\n",
    "            \n",
    "            # Resort these in time:\n",
    "            All_PortIn_Times_sorted,All_PortOut_Times_sorted,All_Port_references_sorted = time_sort(All_PortIn_Times,All_PortOut_Times,All_Port_references)\n",
    "\n",
    "            #extract reward times:\n",
    "            Reward_ts = extract_reward_times(Behav_data[Session])\n",
    "            \n",
    "            # find reward inds and align rewarded ts to poke events:\n",
    "            Rewarded_event_inds = find_reward_inds(All_PortIn_Times_sorted,All_Port_references_sorted,Reward_ts)\n",
    "            Reward_ts = np.asarray(Reward_ts)\n",
    "            Reward_ts = Reward_ts[np.logical_not(np.isnan(Reward_ts))]\n",
    "            Reward_ts = list(Reward_ts)\n",
    "            Reward_ts_aligned = align_trigger_to_index(Reward_ts,Rewarded_event_inds,All_Port_references_sorted)\n",
    "\n",
    "            #extract trial start time stamps\n",
    "            Trial_start_ts = extract_trial_timestamps(Behav_data[Session])\n",
    "\n",
    "            #extract trial end times:\n",
    "            Trial_end_ts = extract_trial_end_times(Behav_data[Session])\n",
    "\n",
    "            #determine trial IDs\n",
    "            trial_id = determine_trial_id(All_PortIn_Times_sorted,Trial_end_ts)\n",
    "\n",
    "            # align trial start and end times to poke events\n",
    "            trialstart_index = find_trialstart_index(trial_id)\n",
    "            trial_start_ts_aligned = align_trial_start_end_timestamps(trial_id,trialstart_index,Trial_start_ts)\n",
    "            trial_end_ts_aligned = align_trial_start_end_timestamps(trial_id,trialstart_index,Trial_end_ts)\n",
    "\n",
    "            #determine LED and reward states for each trial and align them to trials:\n",
    "            IntermediateRewards = []\n",
    "            LED_intensities = []\n",
    "            for item in Behav_data[Session]['SessionData']['SessionVariables']['TLevel']:\n",
    "                TLevel = item\n",
    "                IntermediateRewards = IntermediateRewards + [list(Behav_data[Session]['SessionData']['SessionVariables']['TrainingLevels'][TLevel-1][0:4])]\n",
    "                LED_intensities = LED_intensities + [list(Behav_data[Session]['SessionData']['SessionVariables']['TrainingLevels'][TLevel-1][6:10])]\n",
    "            aligned_LED_intensities = align_trial_start_end_timestamps(trial_id,trialstart_index,LED_intensities)\n",
    "            aligned_IntermediateRewards = align_trial_start_end_timestamps(trial_id,trialstart_index,IntermediateRewards)\n",
    "\n",
    "\n",
    "            Trial_start_Camera_Ts_aligned = ['temporary_spacer'] * len(trial_id)\n",
    "            Trial_end_Camera_Ts_aligned = ['temporary_spacer'] * len(trial_id)\n",
    "            First_poke_Camera_Ts_aligned = ['temporary_spacer'] * len(trial_id)\n",
    "\n",
    "            ## align Training level for each trial:\n",
    "            Training_Levels = align_opto_trials_to_dataframe(trial_id,Behav_data[Session]['SessionData']['SessionVariables']['TLevel'])\n",
    "\n",
    "            # make portin dataframe:\n",
    "            PortIn_df = pd.DataFrame(\n",
    "                {'Trial_id' : trial_id,\n",
    "                 'Trial_Start' : trial_start_ts_aligned,\n",
    "                 'Port': All_Port_references_sorted,\n",
    "                 'PokeIn_Time': All_PortIn_Times_sorted,\n",
    "                 'PokeOut_Time': All_PortOut_Times_sorted,\n",
    "                 'Reward_Times': Reward_ts_aligned,\n",
    "                 'Trial_End' : trial_end_ts_aligned,\n",
    "                 'Port 2,3,4,5 LED intensities': aligned_LED_intensities,\n",
    "                 'Port 1,2,3,4 RewardAmount':aligned_IntermediateRewards,\n",
    "                 'BACK_Trial_Start_Camera_Time' : Trial_start_Camera_Ts_aligned,\n",
    "                 'BACK_Trial_End_Camera_Time' : Trial_end_Camera_Ts_aligned,\n",
    "                 'BACK_First_poke_Camera_Time' : First_poke_Camera_Ts_aligned,\n",
    "                'TrainingLevel': Training_Levels})\n",
    "\n",
    "            #Save Data\n",
    "            PortIn_df.to_csv(Save_path +'/PreProcessed_RawPokeData.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\organised_data\\\\animals\\\\\\\\seq008_implant1\\\\recording4_15-11-2024\\\\\\\\\\\\Preprocessed\\\\\\\\03_20241115_153541_Fri'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
